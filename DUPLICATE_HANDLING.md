# UN-LOCODE Duplicate Handling

## ğŸ¯ AmaÃ§

UN-LOCODE import iÅŸleminde, aynÄ± kod (Ã¶rn: TRIZM) birden fazla kez import edilmeye Ã§alÄ±ÅŸÄ±ldÄ±ÄŸÄ±nda, duplicate kayÄ±tlarÄ±n Ã¶nlenmesi ve sistemin tutarlÄ± kalmasÄ±.

## ğŸ” NasÄ±l Ã‡alÄ±ÅŸÄ±r?

### 1. **Batch Ä°Ã§i Duplicate KontrolÃ¼**
```csharp
// Batch iÃ§inde iÅŸlenen kodlarÄ± takip etmek iÃ§in
var processedCodesInBatch = new HashSet<string>();

// 1) Ã–nce batch iÃ§inde bu kod iÅŸlendi mi kontrol et
if (processedCodesInBatch.Contains(code))
{
    Console.WriteLine($"UNLOCODE kodu batch iÃ§inde zaten iÅŸlendi, skip ediliyor: {code}");
    skipped++;
    continue;
}

// Kod iÅŸlendikten sonra HashSet'e ekle
processedCodesInBatch.Add(code);

// Batch sonrasÄ± HashSet'i temizle
if (batchCount >= batchSize)
{
    await _db.SaveChangesAsync(ct);
    batchCount = 0;
    processedCodesInBatch.Clear(); // Ã–NEMLÄ°!
}
```

### 2. **Database Seviyesi Duplicate KontrolÃ¼**
```csharp
// 2) Database'de bu UNLOCODE kodu zaten var mÄ±?
var existingIdentifier = await _db.LocationIdentifiers
    .AsNoTracking()
    .FirstOrDefaultAsync(i => i.Scheme == CodeScheme.UNLOCODE && i.Code == code, ct);

if (existingIdentifier != null)
{
    // Bu UNLOCODE kodu zaten mevcut, skip et
    Console.WriteLine($"UNLOCODE kodu database'de zaten mevcut, skip ediliyor: {code}");
    skipped++;
    continue;
}
```

### 3. **Unique Constraint**
Database seviyesinde de koruma:
```csharp
// AppDbContext.cs
cfg.HasIndex(x => new { x.Scheme, x.Code }).IsUnique();
```

## ğŸš¨ Batch Processing Sorunu

### **Ã–nceki Problem:**
```csharp
// âŒ YANLIÅ - AynÄ± batch iÃ§inde duplicate eklenebiliyordu
foreach (var record in batch)
{
    // Duplicate kontrolÃ¼ yok
    _db.LocationIdentifiers.Add(new LocationIdentifier { ... });
}

// SaveChanges Ã§aÄŸrÄ±ldÄ±ÄŸÄ±nda unique constraint ihlali!
await _db.SaveChangesAsync(ct);
```

### **Ã‡Ã¶zÃ¼m:**
```csharp
// âœ… DOÄRU - Batch iÃ§inde duplicate kontrolÃ¼
var processedCodesInBatch = new HashSet<string>();

foreach (var record in batch)
{
    if (processedCodesInBatch.Contains(code))
    {
        skipped++;
        continue; // Skip et
    }
    
    processedCodesInBatch.Add(code);
    _db.LocationIdentifiers.Add(new LocationIdentifier { ... });
}

// ArtÄ±k unique constraint ihlali olmayacak
await _db.SaveChangesAsync(ct);
```

## ğŸ“Š Test Senaryosu

### Test DosyasÄ±: `sample-unlocode-batch-duplicate.csv`
```csv
Country,Location,Name,Function,Status
TR,IZM,IZMIR,----34--,AA      # Ä°lk kez - EKLENECEK
TR,IST,ISTANBUL,----34--,AA    # Ä°lk kez - EKLENECEK
TR,IZM,IZMIR,----34--,AA      # Batch iÃ§inde duplicate - SKIP EDÄ°LECEK
TR,IST,ISTANBUL,----34--,AA    # Batch iÃ§inde duplicate - SKIP EDÄ°LECEK
US,NYC,NEW YORK,----34--,AA    # Ä°lk kez - EKLENECEK
```

### Beklenen SonuÃ§:
```
Total Rows: 18
Locations Inserted: 8 (benzersiz lokasyonlar)
Identifiers Inserted: 8 (benzersiz UNLOCODE kodlarÄ±)
Locations Updated: 0
Skipped: 10 (batch iÃ§i + database duplicate'larÄ±)
```

## ğŸ”§ Teknik Detaylar

### ImportResult SÄ±nÄ±fÄ±
```csharp
public record ImportResult(
    int RowsRead,           // Toplam okunan satÄ±r
    int LocationsInserted,  // Yeni eklenen lokasyonlar
    int IdentifiersInserted, // Yeni eklenen identifier'lar
    int LocationsUpdated,   // GÃ¼ncellenen lokasyonlar
    int Skipped = 0         // Skip edilen kayÄ±tlar (batch + database)
);
```

### Skip Edilen KayÄ±tlar
- **Batch iÃ§i duplicate'lar**: AynÄ± batch iÃ§inde aynÄ± kod
- **Database duplicate'larÄ±**: Database'de zaten mevcut kod
- **BoÅŸ/geÃ§ersiz kayÄ±tlar**: Country veya Location boÅŸ
- **Hata oluÅŸan kayÄ±tlar**: Exception durumunda

## ğŸ“ Log Ã–rnekleri

### Console Ã‡Ä±ktÄ±sÄ±:
```
UNLOCODE kodu batch iÃ§inde zaten iÅŸlendi, skip ediliyor: TRIZM
UNLOCODE kodu batch iÃ§inde zaten iÅŸlendi, skip ediliyor: TRIST
UNLOCODE kodu database'de zaten mevcut, skip ediliyor: USNYC
LocationIdentifier ekleniyor: DEBER, extra: {"Function":"----34--","Status":"AA","Date":"2407","IATA":"BER","Coordinates":"5231N 01324E"}
```

### Import Sonucu:
```json
{
  "totalRows": 18,
  "locationsInserted": 8,
  "identifiersInserted": 8,
  "locationsUpdated": 0,
  "skipped": 10
}
```

## ğŸ§ª Test Etme

### 1. **Test Script'ini Ã‡alÄ±ÅŸtÄ±rÄ±n**
```bash
# Test script'ini Ã§alÄ±ÅŸtÄ±r
./test-batch-duplicate.sh

# Manuel test
curl -X POST \
  -H "Authorization: Bearer {token}" \
  -F "file=@test-data/sample-unlocode-batch-duplicate.csv" \
  http://localhost:8080/api/platform/location-import/import/unlocode
```

### 2. **Frontend'den Test Edin**
- `/super/location-import` sayfasÄ±na gidin
- `sample-unlocode-batch-duplicate.csv` dosyasÄ±nÄ± yÃ¼kleyin
- SonuÃ§larÄ± kontrol edin

### 3. **Database KontrolÃ¼**
```sql
-- LocationIdentifier'da kaÃ§ tane UNLOCODE var?
SELECT COUNT(*) FROM LocationIdentifiers WHERE Scheme = 'UNLOCODE';

-- Hangi kodlar var?
SELECT Code, LocationId FROM LocationIdentifiers WHERE Scheme = 'UNLOCODE';

-- Duplicate var mÄ± kontrol et?
SELECT Code, COUNT(*) FROM LocationIdentifiers 
WHERE Scheme = 'UNLOCODE' 
GROUP BY Code 
HAVING COUNT(*) > 1;
```

## âš ï¸ Dikkat Edilecekler

### 1. **Memory Management**
- `HashSet<string>` batch boyutu kadar memory kullanÄ±r
- Batch sonrasÄ± `Clear()` Ã§aÄŸrÄ±lmasÄ± Ã¶nemli
- BÃ¼yÃ¼k dosyalar iÃ§in batch size optimize edilmeli

### 2. **Performance**
- `HashSet.Contains()` O(1) complexity
- Database query'leri minimize edildi
- Batch processing optimize edildi

### 3. **Error Handling**
- Unique constraint ihlali artÄ±k olmayacak
- Graceful degradation saÄŸlandÄ±
- DetaylÄ± logging eklendi

## ğŸ”„ Gelecek GeliÅŸtirmeler

### 1. **Advanced Duplicate Detection**
- Fuzzy matching ile benzer kodlar
- Levenshtein distance hesaplama
- Auto-correction Ã¶nerileri

### 2. **Batch Size Optimization**
- Dinamik batch size
- Memory usage monitoring
- Performance metrics

### 3. **Duplicate Reporting**
- Hangi kayÄ±tlarÄ±n neden skip edildiÄŸi
- Skip sebeplerinin kategorize edilmesi
- Export functionality

## ğŸ“š Ä°lgili Dosyalar

- `LocationImportService.cs` - Ana import logic (gÃ¼ncellendi)
- `ImportResult.cs` - SonuÃ§ modeli (skipped eklendi)
- `AppDbContext.cs` - Database constraint'ler
- `sample-unlocode-batch-duplicate.csv` - Test dosyasÄ±
- `test-batch-duplicate.sh` - Test script'i

## ğŸ‰ SonuÃ§

Batch processing duplicate handling sistemi sayesinde:
- âœ… **Data integrity** korunur (unique constraint ihlali yok)
- âœ… **Performance** artar (gereksiz database iÅŸlemleri yok)
- âœ… **Memory efficiency** saÄŸlanÄ±r (HashSet optimization)
- âœ… **User experience** iyileÅŸir (net sonuÃ§lar)
- âœ… **Error handling** robust olur (graceful degradation)

Sistem artÄ±k production'da gÃ¼venle kullanÄ±labilir! ğŸš€
